{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ProRNJhsHVq",
        "outputId": "66f181bd-479e-41fd-ff8c-cd74d3a247fc"
      },
      "id": "5ProRNJhsHVq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage import label\n",
        "\n",
        "# Configuration matching original training\n",
        "class FineTuningConfig:\n",
        "    pretrained_path = \"/content/drive/MyDrive/BPEYE/best_seg.pth\"\n",
        "    train_img_dir = \"/content/drive/MyDrive/BPEYE/DATASET /GLAUCOMA/REFUGE2/train/images\"\n",
        "    train_mask_dir = \"/content/drive/MyDrive/BPEYE/DATASET /GLAUCOMA/REFUGE2/train/mask\"\n",
        "    val_img_dir = \"/content/drive/MyDrive/BPEYE/DATASET /GLAUCOMA/REFUGE2/val/images\"\n",
        "    val_mask_dir = \"/content/drive/MyDrive/BPEYE/DATASET /GLAUCOMA/REFUGE2/val/mask\"\n",
        "    output_dir = \"/content/drive/MyDrive/BPEYE/fine_tuned_models\"\n",
        "\n",
        "    # Training parameters (matching original)\n",
        "    lr = 1e-4\n",
        "    batch_size = 8\n",
        "    num_workers = 4\n",
        "    total_epoch = 20  # Fewer epochs for fine-tuning\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    output_size = (256, 256)\n",
        "\n",
        "    # Fine-tuning specific\n",
        "    freeze_encoder_epochs = 5  # First 5 epochs with frozen encoder\n",
        "\n",
        "config = FineTuningConfig()\n",
        "\n",
        "# Fixed FlexibleDataLoader (same as before but simplified)\n",
        "class FlexibleDataLoader:\n",
        "    def __init__(self, image_dir, mask_dir, image_extensions=None, mask_extensions=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "\n",
        "        if image_extensions is None:\n",
        "            self.image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
        "        else:\n",
        "            self.image_extensions = [ext.lower() for ext in image_extensions]\n",
        "\n",
        "        if mask_extensions is None:\n",
        "            self.mask_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif']\n",
        "        else:\n",
        "            self.mask_extensions = [ext.lower() for ext in mask_extensions]\n",
        "\n",
        "        self.image_paths, self.mask_paths = self._match_files()\n",
        "        print(f\"Found {len(self.image_paths)} matched image-mask pairs\")\n",
        "\n",
        "    def _get_files_with_extensions(self, directory, extensions):\n",
        "        files = []\n",
        "        if not os.path.exists(directory):\n",
        "            print(f\"Warning: Directory {directory} does not exist\")\n",
        "            return files\n",
        "\n",
        "        for filename in os.listdir(directory):\n",
        "            file_ext = os.path.splitext(filename)[1].lower()\n",
        "            if file_ext in extensions and not filename.startswith('.'):\n",
        "                files.append(os.path.join(directory, filename))\n",
        "        return sorted(files)\n",
        "\n",
        "    def _match_files(self):\n",
        "        image_files = self._get_files_with_extensions(self.image_dir, self.image_extensions)\n",
        "        mask_files = self._get_files_with_extensions(self.mask_dir, self.mask_extensions)\n",
        "\n",
        "        image_dict = {}\n",
        "        mask_dict = {}\n",
        "\n",
        "        for img_path in image_files:\n",
        "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "            image_dict[base_name] = img_path\n",
        "\n",
        "        for mask_path in mask_files:\n",
        "            base_name = os.path.splitext(os.path.basename(mask_path))[0]\n",
        "            mask_dict[base_name] = mask_path\n",
        "\n",
        "        matched_images = []\n",
        "        matched_masks = []\n",
        "\n",
        "        for base_name in image_dict:\n",
        "            if base_name in mask_dict:\n",
        "                matched_images.append(image_dict[base_name])\n",
        "                matched_masks.append(mask_dict[base_name])\n",
        "\n",
        "        return matched_images, matched_masks\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.image_paths, self.mask_paths\n",
        "\n",
        "# Dataset class (adapted from original)\n",
        "class GlaucomaDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, output_size=(256, 256)):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        img = transforms.functional.to_tensor(img)\n",
        "        img = transforms.functional.resize(img, self.output_size, interpolation=Image.BILINEAR)\n",
        "\n",
        "        # Load mask - your format: OD=grey(128), OC=black(0), background=white(255)\n",
        "        mask = np.array(Image.open(self.mask_paths[idx], mode='r'))\n",
        "\n",
        "        # Convert to binary masks like in original training\n",
        "        # OD: grey areas (128) -> channel 0\n",
        "        # OC: black areas (0) -> channel 1\n",
        "        od = (mask == 128).astype(np.float32)  # Optic disc\n",
        "        oc = (mask == 0).astype(np.float32)    # Optic cup\n",
        "\n",
        "        od = torch.from_numpy(od[None, :, :])\n",
        "        oc = torch.from_numpy(oc[None, :, :])\n",
        "        od = transforms.functional.resize(od, self.output_size, interpolation=Image.NEAREST)\n",
        "        oc = transforms.functional.resize(oc, self.output_size, interpolation=Image.NEAREST)\n",
        "        seg = torch.cat([od, oc], dim=0)\n",
        "\n",
        "        return img, seg\n",
        "\n",
        "# UNet Model (same as original)\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=2):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.epoch = 0\n",
        "\n",
        "        # Encoder\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "        self.down5 = Down(1024, 2048)\n",
        "\n",
        "        factor = 2\n",
        "        self.down6 = Down(2048, 4096 // factor)\n",
        "\n",
        "        # Decoder\n",
        "        self.up1 = Up(4096, 2048 // factor)\n",
        "        self.up2 = Up(2048, 1024 // factor)\n",
        "        self.up3 = Up(1024, 512 // factor)\n",
        "        self.up4 = Up(512, 256 // factor)\n",
        "        self.up5 = Up(256, 128 // factor)\n",
        "        self.up6 = Up(128, 64)\n",
        "        self.output_layer = OutConv(64, n_classes)\n",
        "\n",
        "        # Define encoder modules for freezing (like original approach)\n",
        "        self.encoder_modules = [\n",
        "            self.inc, self.down1, self.down2, self.down3,\n",
        "            self.down4, self.down5, self.down6\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x6 = self.down5(x5)\n",
        "        x7 = self.down6(x6)\n",
        "\n",
        "        out = self.up1(x7, x6)\n",
        "        out = self.up2(out, x5)\n",
        "        out = self.up3(out, x4)\n",
        "        out = self.up4(out, x3)\n",
        "        out = self.up5(out, x2)\n",
        "        out = self.up6(out, x1)\n",
        "        out = self.output_layer(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def freeze_encoder(self):\n",
        "        \"\"\"Freeze encoder parameters\"\"\"\n",
        "        for module in self.encoder_modules:\n",
        "            for param in module.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def unfreeze_encoder(self):\n",
        "        \"\"\"Unfreeze encoder parameters\"\"\"\n",
        "        for module in self.encoder_modules:\n",
        "            for param in module.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "# Metrics and utilities (from original code)\n",
        "EPS = 1e-7\n",
        "\n",
        "def compute_dice_coef(input, target):\n",
        "    batch_size = input.shape[0]\n",
        "    return sum([dice_coef_sample(input[k,:,:], target[k,:,:]) for k in range(batch_size)])/batch_size\n",
        "\n",
        "def dice_coef_sample(input, target):\n",
        "    iflat = input.contiguous().view(-1)\n",
        "    tflat = target.contiguous().view(-1)\n",
        "    intersection = (iflat * tflat).sum()\n",
        "    return (2. * intersection) / (iflat.sum() + tflat.sum())\n",
        "\n",
        "def vertical_diameter(binary_segmentation):\n",
        "    vertical_axis_diameter = np.sum(binary_segmentation, axis=1)\n",
        "    diameter = np.max(vertical_axis_diameter, axis=1)\n",
        "    return diameter\n",
        "\n",
        "def vertical_cup_to_disc_ratio(od, oc):\n",
        "    cup_diameter = vertical_diameter(oc)\n",
        "    disc_diameter = vertical_diameter(od)\n",
        "    return cup_diameter / (disc_diameter + EPS)\n",
        "\n",
        "def compute_vCDR_error(pred_od, pred_oc, gt_od, gt_oc):\n",
        "    pred_vCDR = vertical_cup_to_disc_ratio(pred_od, pred_oc)\n",
        "    gt_vCDR = vertical_cup_to_disc_ratio(gt_od, gt_oc)\n",
        "    vCDR_err = np.mean(np.abs(gt_vCDR - pred_vCDR))\n",
        "    return vCDR_err, pred_vCDR, gt_vCDR\n",
        "\n",
        "def refine_seg(pred):\n",
        "    \"\"\"Only retain the biggest connected component\"\"\"\n",
        "    np_pred = pred.numpy()\n",
        "\n",
        "    largest_ccs = []\n",
        "    for i in range(np_pred.shape[0]):\n",
        "        labeled, ncomponents = label(np_pred[i,:,:])\n",
        "        bincounts = np.bincount(labeled.flat)[1:]\n",
        "        if len(bincounts) == 0:\n",
        "            largest_cc = labeled == 0\n",
        "        else:\n",
        "            largest_cc = labeled == np.argmax(bincounts)+1\n",
        "        largest_cc = torch.tensor(largest_cc, dtype=torch.float32)\n",
        "        largest_ccs.append(largest_cc)\n",
        "    largest_ccs = torch.stack(largest_ccs)\n",
        "\n",
        "    return largest_ccs\n",
        "\n",
        "# Setup data loaders\n",
        "def setup_data_loaders():\n",
        "    print(\"Setting up data loaders...\")\n",
        "\n",
        "    # Create data loaders\n",
        "    train_data_loader = FlexibleDataLoader(config.train_img_dir, config.train_mask_dir)\n",
        "    val_data_loader = FlexibleDataLoader(config.val_img_dir, config.val_mask_dir)\n",
        "\n",
        "    train_image_paths, train_mask_paths = train_data_loader.get_data()\n",
        "    val_image_paths, val_mask_paths = val_data_loader.get_data()\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = GlaucomaDataset(train_image_paths, train_mask_paths, config.output_size)\n",
        "    val_dataset = GlaucomaDataset(val_image_paths, val_mask_paths, config.output_size)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Fine-tuning function (based on original training loop)\n",
        "def fine_tune_model():\n",
        "    print(\"Starting fine-tuning process...\")\n",
        "\n",
        "    # Setup data\n",
        "    train_loader, val_loader = setup_data_loaders()\n",
        "\n",
        "    # Setup model\n",
        "    model = UNet(n_channels=3, n_classes=2).to(config.device)\n",
        "\n",
        "    # Load pretrained weights\n",
        "    if os.path.exists(config.pretrained_path):\n",
        "        model.load_state_dict(torch.load(config.pretrained_path, map_location=config.device))\n",
        "        print(f\"✅ Loaded pretrained model from {config.pretrained_path}\")\n",
        "    else:\n",
        "        print(f\"❌ Pretrained model not found at {config.pretrained_path}\")\n",
        "        return\n",
        "\n",
        "    # Setup loss and optimizer (same as original)\n",
        "    seg_loss = torch.nn.BCELoss(reduction='mean')\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(config.output_dir, exist_ok=True)\n",
        "\n",
        "    # Training parameters\n",
        "    nb_train_batches = len(train_loader)\n",
        "    nb_val_batches = len(val_loader)\n",
        "    best_val_auc = 0.\n",
        "\n",
        "    print(f\"Training batches: {nb_train_batches}, Validation batches: {nb_val_batches}\")\n",
        "\n",
        "    while model.epoch < config.total_epoch:\n",
        "        # Freeze encoder for first few epochs\n",
        "        if model.epoch < config.freeze_encoder_epochs:\n",
        "            model.freeze_encoder()\n",
        "            print(f\"Epoch {model.epoch + 1}: Encoder FROZEN\")\n",
        "        else:\n",
        "            model.unfreeze_encoder()\n",
        "            if model.epoch == config.freeze_encoder_epochs:\n",
        "                print(f\"Epoch {model.epoch + 1}: Encoder UNFROZEN\")\n",
        "\n",
        "        # Training accumulators\n",
        "        train_loss, val_loss = 0., 0.\n",
        "        train_dsc_od, val_dsc_od = 0., 0.\n",
        "        train_dsc_oc, val_dsc_oc = 0., 0.\n",
        "        train_vCDR_error, val_vCDR_error = 0., 0.\n",
        "\n",
        "        ############\n",
        "        # TRAINING #\n",
        "        ############\n",
        "        model.train()\n",
        "        train_data = iter(train_loader)\n",
        "        for k in range(nb_train_batches):\n",
        "            # Load data\n",
        "            imgs, seg_gts = next(train_data)\n",
        "            imgs, seg_gts = imgs.to(config.device), seg_gts.to(config.device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(imgs)\n",
        "            loss = seg_loss(logits, seg_gts)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() / nb_train_batches\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Compute segmentation metrics\n",
        "                pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(config.device)\n",
        "                pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(config.device)\n",
        "                gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
        "                gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n",
        "\n",
        "                dsc_od = compute_dice_coef(pred_od, gt_od)\n",
        "                dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
        "                train_dsc_od += dsc_od.item()/nb_train_batches\n",
        "                train_dsc_oc += dsc_oc.item()/nb_train_batches\n",
        "\n",
        "                # Compute vCDR error\n",
        "                vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(\n",
        "                    pred_od.cpu().numpy(), pred_oc.cpu().numpy(),\n",
        "                    gt_od.cpu().numpy(), gt_oc.cpu().numpy()\n",
        "                )\n",
        "                train_vCDR_error += vCDR_error / nb_train_batches\n",
        "\n",
        "            # Progress\n",
        "            print(f'Epoch {model.epoch+1}, iter {k+1}/{nb_train_batches}, loss {loss.item():.6f}' + ' '*20, end='\\r')\n",
        "\n",
        "        ##############\n",
        "        # VALIDATION #\n",
        "        ##############\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_data = iter(val_loader)\n",
        "            for k in range(nb_val_batches):\n",
        "                # Load data\n",
        "                imgs, seg_gts = next(val_data)\n",
        "                imgs, seg_gts = imgs.to(config.device), seg_gts.to(config.device)\n",
        "\n",
        "                # Forward pass\n",
        "                logits = model(imgs)\n",
        "                val_loss += seg_loss(logits, seg_gts).item() / nb_val_batches\n",
        "\n",
        "                # Compute segmentation metrics\n",
        "                pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(config.device)\n",
        "                pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(config.device)\n",
        "                gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
        "                gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n",
        "\n",
        "                dsc_od = compute_dice_coef(pred_od, gt_od)\n",
        "                dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
        "                val_dsc_od += dsc_od.item()/nb_val_batches\n",
        "                val_dsc_oc += dsc_oc.item()/nb_val_batches\n",
        "\n",
        "                vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(\n",
        "                    pred_od.cpu().numpy(), pred_oc.cpu().numpy(),\n",
        "                    gt_od.cpu().numpy(), gt_oc.cpu().numpy()\n",
        "                )\n",
        "                val_vCDR_error += vCDR_error / nb_val_batches\n",
        "\n",
        "                print(f'Validation iter {k+1}/{nb_val_batches}' + ' '*50, end='\\r')\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f'FINE-TUNING epoch {model.epoch+1}' + ' '*50)\n",
        "        print(f'LOSSES: {train_loss:.4f} (train), {val_loss:.4f} (val)')\n",
        "        print(f'OD segmentation (Dice Score): {train_dsc_od:.4f} (train), {val_dsc_od:.4f} (val)')\n",
        "        print(f'OC segmentation (Dice Score): {train_dsc_oc:.4f} (train), {val_dsc_oc:.4f} (val)')\n",
        "        print(f'vCDR error: {train_vCDR_error:.4f} (train), {val_vCDR_error:.4f} (val)')\n",
        "\n",
        "        # Save model if best validation performance is reached\n",
        "        current_val_score = val_dsc_od + val_dsc_oc\n",
        "        if current_val_score > best_val_auc:\n",
        "            model_path = os.path.join(config.output_dir, f'fine_tuned_best.pth')\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            best_val_auc = current_val_score\n",
        "            print(f'✅ Best validation score reached: {current_val_score:.4f}. Model saved.')\n",
        "\n",
        "        print('_'*50)\n",
        "\n",
        "        # End of epoch\n",
        "        model.epoch += 1\n",
        "\n",
        "    print(\"Fine-tuning completed!\")\n",
        "    print(f\"Best validation score: {best_val_auc:.4f}\")\n",
        "    print(f\"Models saved in: {config.output_dir}\")\n",
        "\n",
        "# Run fine-tuning\n",
        "if __name__ == \"__main__\":\n",
        "    fine_tune_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otYJizq4_xcc",
        "outputId": "578401da-0b1f-4858-817c-98f7e241cc0c"
      },
      "id": "otYJizq4_xcc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning process...\n",
            "Setting up data loaders...\n",
            "Found 400 matched image-mask pairs\n",
            "Found 400 matched image-mask pairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded pretrained model from /content/drive/MyDrive/BPEYE/best_seg.pth\n",
            "Training batches: 50, Validation batches: 50\n",
            "Epoch 1: Encoder FROZEN\n",
            "FINE-TUNING epoch 1                                                  \n",
            "LOSSES: 0.0049 (train), 0.0062 (val)\n",
            "OD segmentation (Dice Score): 0.8856 (train), 0.8354 (val)\n",
            "OC segmentation (Dice Score): 0.8648 (train), 0.7645 (val)\n",
            "vCDR error: 0.0843 (train), 0.1187 (val)\n",
            "✅ Best validation score reached: 1.5999. Model saved.\n",
            "__________________________________________________\n",
            "Epoch 2: Encoder FROZEN\n",
            "FINE-TUNING epoch 2                                                  \n",
            "LOSSES: 0.0042 (train), 0.0057 (val)\n",
            "OD segmentation (Dice Score): 0.8956 (train), 0.8506 (val)\n",
            "OC segmentation (Dice Score): 0.8744 (train), 0.7928 (val)\n",
            "vCDR error: 0.0885 (train), 0.1010 (val)\n",
            "✅ Best validation score reached: 1.6434. Model saved.\n",
            "__________________________________________________\n",
            "Epoch 3: Encoder FROZEN\n",
            "FINE-TUNING epoch 3                                                  \n",
            "LOSSES: 0.0041 (train), 0.0055 (val)\n",
            "OD segmentation (Dice Score): 0.8997 (train), 0.8605 (val)\n",
            "OC segmentation (Dice Score): 0.8789 (train), 0.7857 (val)\n",
            "vCDR error: 0.0855 (train), 0.1401 (val)\n",
            "✅ Best validation score reached: 1.6462. Model saved.\n",
            "__________________________________________________\n",
            "Epoch 4: Encoder FROZEN\n",
            "FINE-TUNING epoch 4                                                  \n",
            "LOSSES: 0.0039 (train), 0.0064 (val)\n",
            "OD segmentation (Dice Score): 0.9048 (train), 0.8295 (val)\n",
            "OC segmentation (Dice Score): 0.8821 (train), 0.7589 (val)\n",
            "vCDR error: 0.0860 (train), 0.1599 (val)\n",
            "__________________________________________________\n",
            "Epoch 5: Encoder FROZEN\n",
            "FINE-TUNING epoch 5                                                  \n",
            "LOSSES: 0.0037 (train), 0.0067 (val)\n",
            "OD segmentation (Dice Score): 0.9087 (train), 0.8236 (val)\n",
            "OC segmentation (Dice Score): 0.8876 (train), 0.7659 (val)\n",
            "vCDR error: 0.0780 (train), 0.1329 (val)\n",
            "__________________________________________________\n",
            "Epoch 6: Encoder UNFROZEN\n",
            "FINE-TUNING epoch 6                                                  \n",
            "LOSSES: 0.0038 (train), 0.0054 (val)\n",
            "OD segmentation (Dice Score): 0.9045 (train), 0.8570 (val)\n",
            "OC segmentation (Dice Score): 0.8842 (train), 0.8185 (val)\n",
            "vCDR error: 0.0991 (train), 0.0796 (val)\n",
            "✅ Best validation score reached: 1.6755. Model saved.\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 7                                                  \n",
            "LOSSES: 0.0036 (train), 0.0084 (val)\n",
            "OD segmentation (Dice Score): 0.9093 (train), 0.7971 (val)\n",
            "OC segmentation (Dice Score): 0.8908 (train), 0.7222 (val)\n",
            "vCDR error: 0.0858 (train), 0.1962 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 8                                                  \n",
            "LOSSES: 0.0032 (train), 0.0065 (val)\n",
            "OD segmentation (Dice Score): 0.9195 (train), 0.8328 (val)\n",
            "OC segmentation (Dice Score): 0.9039 (train), 0.7730 (val)\n",
            "vCDR error: 0.0650 (train), 0.1307 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 9                                                  \n",
            "LOSSES: 0.0030 (train), 0.0057 (val)\n",
            "OD segmentation (Dice Score): 0.9248 (train), 0.8499 (val)\n",
            "OC segmentation (Dice Score): 0.9127 (train), 0.7900 (val)\n",
            "vCDR error: 0.0576 (train), 0.2193 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 10                                                  \n",
            "LOSSES: 0.0028 (train), 0.0063 (val)\n",
            "OD segmentation (Dice Score): 0.9294 (train), 0.8378 (val)\n",
            "OC segmentation (Dice Score): 0.9193 (train), 0.7877 (val)\n",
            "vCDR error: 0.0549 (train), 0.2151 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 11                                                  \n",
            "LOSSES: 0.0026 (train), 0.0068 (val)\n",
            "OD segmentation (Dice Score): 0.9327 (train), 0.8371 (val)\n",
            "OC segmentation (Dice Score): 0.9263 (train), 0.7840 (val)\n",
            "vCDR error: 0.0498 (train), 0.1344 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 12                                                  \n",
            "LOSSES: 0.0024 (train), 0.0082 (val)\n",
            "OD segmentation (Dice Score): 0.9383 (train), 0.8214 (val)\n",
            "OC segmentation (Dice Score): 0.9368 (train), 0.7581 (val)\n",
            "vCDR error: 0.0435 (train), 0.1353 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 13                                                  \n",
            "LOSSES: 0.0023 (train), 0.0061 (val)\n",
            "OD segmentation (Dice Score): 0.9414 (train), 0.8641 (val)\n",
            "OC segmentation (Dice Score): 0.9381 (train), 0.8062 (val)\n",
            "vCDR error: 0.0386 (train), 0.1088 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 14                                                  \n",
            "LOSSES: 0.0022 (train), 0.0072 (val)\n",
            "OD segmentation (Dice Score): 0.9433 (train), 0.8463 (val)\n",
            "OC segmentation (Dice Score): 0.9382 (train), 0.7754 (val)\n",
            "vCDR error: 0.0389 (train), 0.1899 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 15                                                  \n",
            "LOSSES: 0.0020 (train), 0.0063 (val)\n",
            "OD segmentation (Dice Score): 0.9470 (train), 0.8603 (val)\n",
            "OC segmentation (Dice Score): 0.9438 (train), 0.8199 (val)\n",
            "vCDR error: 0.0378 (train), 0.0763 (val)\n",
            "✅ Best validation score reached: 1.6802. Model saved.\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 16                                                  \n",
            "LOSSES: 0.0019 (train), 0.0063 (val)\n",
            "OD segmentation (Dice Score): 0.9518 (train), 0.8672 (val)\n",
            "OC segmentation (Dice Score): 0.9484 (train), 0.8087 (val)\n",
            "vCDR error: 0.0392 (train), 0.0799 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 17                                                  \n",
            "LOSSES: 0.0017 (train), 0.0083 (val)\n",
            "OD segmentation (Dice Score): 0.9536 (train), 0.8419 (val)\n",
            "OC segmentation (Dice Score): 0.9522 (train), 0.7850 (val)\n",
            "vCDR error: 0.0332 (train), 0.1254 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 18                                                  \n",
            "LOSSES: 0.0017 (train), 0.0064 (val)\n",
            "OD segmentation (Dice Score): 0.9553 (train), 0.8691 (val)\n",
            "OC segmentation (Dice Score): 0.9537 (train), 0.8086 (val)\n",
            "vCDR error: 0.0320 (train), 0.0809 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 19                                                  \n",
            "LOSSES: 0.0017 (train), 0.0079 (val)\n",
            "OD segmentation (Dice Score): 0.9573 (train), 0.8448 (val)\n",
            "OC segmentation (Dice Score): 0.9517 (train), 0.7878 (val)\n",
            "vCDR error: 0.0335 (train), 0.1001 (val)\n",
            "__________________________________________________\n",
            "FINE-TUNING epoch 20                                                  \n",
            "LOSSES: 0.0016 (train), 0.0078 (val)\n",
            "OD segmentation (Dice Score): 0.9592 (train), 0.8529 (val)\n",
            "OC segmentation (Dice Score): 0.9557 (train), 0.7892 (val)\n",
            "vCDR error: 0.0297 (train), 0.0933 (val)\n",
            "__________________________________________________\n",
            "Fine-tuning completed!\n",
            "Best validation score: 1.6802\n",
            "Models saved in: /content/drive/MyDrive/BPEYE/fine_tuned_models\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}